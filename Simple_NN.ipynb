{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e3fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uproot as ur\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset , DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e163ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_output -> number of inputs variables\n",
    "N_layer1 = 25\n",
    "N_layer2 = 25\n",
    "N_layer3 = 25\n",
    "N_layer4 = 25\n",
    "\n",
    "do_dropout = True\n",
    "Drop_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6bd7485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4312/3957282208.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  file = pd.read_csv('./fracdata.csv',' ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['seqNumber', 'runNumber', 'eventNumber', 'avgMu', 'nPrimVtx', 'jetCnt',\n",
       "       'jetCalE', 'jetCalPt', 'jetCalEta', 'jetCalPhi', 'jetRawE', 'jetRawPt',\n",
       "       'jetRawEta', 'jetRawPhi', 'jetNConst', 'truthJetMatchRadius',\n",
       "       'truthJetE', 'truthJetPt', 'truthJetRap', 'truthJetPhi', 'nCluster',\n",
       "       'clusterIndex', 'cluster_nCells', 'cluster_nCells_tot', 'clusterECalib',\n",
       "       'clusterPtCalib', 'clusterEtaCalib', 'clusterPhiCalib',\n",
       "       'cluster_sumCellECalib', 'cluster_fracECalib', 'cluster_fracECalib_ref',\n",
       "       'clusterE', 'clusterPt', 'clusterEta', 'clusterPhi', 'cluster_sumCellE',\n",
       "       'cluster_time', 'cluster_fracE', 'cluster_fracE_ref',\n",
       "       'cluster_EM_PROBABILITY', 'cluster_HAD_WEIGHT', 'cluster_OOC_WEIGHT',\n",
       "       'cluster_DM_WEIGHT', 'cluster_ENG_CALIB_TOT', 'cluster_ENG_CALIB_OUT_T',\n",
       "       'cluster_ENG_CALIB_OUT_L', 'cluster_ENG_CALIB_OUT_M',\n",
       "       'cluster_ENG_CALIB_DEAD_T', 'cluster_ENG_CALIB_DEAD_L',\n",
       "       'cluster_ENG_CALIB_DEAD_M', 'cluster_ENG_CALIB_DEAD_TOT',\n",
       "       'cluster_ENG_CALIB_FRAC_EM', 'cluster_ENG_CALIB_FRAC_HAD',\n",
       "       'cluster_ENG_CALIB_FRAC_REST', 'cluster_CENTER_MAG',\n",
       "       'cluster_FIRST_ENG_DENS', 'cluster_FIRST_PHI', 'cluster_FIRST_ETA',\n",
       "       'cluster_SECOND_R', 'cluster_SECOND_LAMBDA', 'cluster_DELTA_PHI',\n",
       "       'cluster_DELTA_THETA', 'cluster_DELTA_ALPHA', 'cluster_CENTER_X',\n",
       "       'cluster_CENTER_Y', 'cluster_CENTER_Z', 'cluster_CENTER_LAMBDA',\n",
       "       'cluster_LATERAL', 'cluster_LONGITUDINAL', 'cluster_ENG_FRAC_EM',\n",
       "       'cluster_ENG_FRAC_MAX', 'cluster_ENG_FRAC_CORE',\n",
       "       'cluster_SECOND_ENG_DENS', 'cluster_ISOLATION', 'cluster_ENG_BAD_CELLS',\n",
       "       'cluster_N_BAD_CELLS', 'cluster_N_BAD_CELLS_CORR',\n",
       "       'cluster_BAD_CELLS_CORR_E', 'cluster_BADLARQ_FRAC', 'cluster_ENG_POS',\n",
       "       'cluster_SIGNIFICANCE', 'cluster_CELL_SIGNIFICANCE',\n",
       "       'cluster_CELL_SIG_SAMPLING', 'cluster_AVG_LAR_Q', 'cluster_AVG_TILE_Q',\n",
       "       'cluster_ENG_BAD_HV_CELLS', 'cluster_N_BAD_HV_CELLS', 'cluster_PTD',\n",
       "       'cluster_MASS', 'cluster_SECOND_TIME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.read_csv('./fracdata.csv',' ')\n",
    "\n",
    "#df = file.arrays(library=\"pd\")\n",
    "df1 = file.head(70000)\n",
    "#df1.columns\n",
    "df1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c14a31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for event in eventNumbers:\n",
    "tempE = []\n",
    "tempEta = []\n",
    "temp_time = []\n",
    "temp_labels = []\n",
    "count_jets = 1\n",
    "old_event = df1['jetCnt'][0]\n",
    "old_jetCnt = df1['jetCnt'][0]\n",
    "change_bol = False\n",
    "\n",
    "clusterE = []\n",
    "clusterEta = []\n",
    "cluster_time = []\n",
    "labels = []\n",
    "\n",
    "for index,row in df1.iterrows():\n",
    "    \n",
    "    clusterE.append(row['clusterE'])\n",
    "    clusterEta.append(row['clusterEtaCalib'])\n",
    "    cluster_time.append(row['cluster_time'])\n",
    "    labels.append( int(row['cluster_ENG_CALIB_TOT'] <= 0) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff0e79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create Dictionary containing data and labels\n",
    "\n",
    "Dictionary_data ={\n",
    "    \"0\": clusterE,\n",
    "    \"1\": clusterEta,\n",
    "    \"2\": cluster_time,\n",
    "    \"label\": labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b50208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dictionary_data[\"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d538d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go to use an simple Neural Network :3 :3 :3\n",
    "class NN_pileup(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN_pileup,self).__init__()\n",
    "\n",
    "        self.Drop = nn.Dropout( Drop_rate ) #0.25 debo testear esto hasta encontrar lo mejor!!!\n",
    "        \n",
    "        self.layer1 = nn.Linear(len(Dictionary_data)-1 ,N_layer1)   \n",
    "        self.layer2 = nn.Linear(N_layer1,N_layer2) \n",
    "        self.layer3 = nn.Linear(N_layer2,N_layer3) \n",
    "        self.layer4 = nn.Linear(N_layer3,1) \n",
    "        #self.layer5 = nn.Linear(N_layer4,1)  \n",
    "        \n",
    "        self.activationReLU = nn.ReLU()\n",
    "        self.activationLeaky = nn.LeakyReLU()\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def  forward(self,x): #\"pass the input through each of our operators\"\n",
    "        x = self.layer1(x)\n",
    "        x = self.activationReLU(x)\n",
    "        if do_dropout ==True:\n",
    "            x = self.Drop(x)   ###!!!!!!!!!!!!\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        x = self.activationReLU(x)\n",
    "        if do_dropout ==True:\n",
    "            x = self.Drop(x)   ###!!!!!!!!!!!!\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.activationReLU(x)\n",
    "\n",
    "        if do_dropout ==True:\n",
    "            x = self.Drop(x)   ###!!!!!!!!!!!!\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "        '''\n",
    "        x = self.activationReLU(x)\n",
    "        if do_dropout ==True:\n",
    "            x = self.Drop(x)   ###!!!!!!!!!!!!\n",
    "        \n",
    "        x = self.layer5(x)\n",
    "        '''\n",
    "        x = nn.functional.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff68f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet_train(torch.utils.data.Dataset):\n",
    "    def __init__(self, Dictionary_data):\n",
    "    \n",
    "        #self.filename = filename\n",
    "        self.EM14 = 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(Dictionary_data[\"1\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        features = []\n",
    "        \n",
    "        for i in range (0,len(Dictionary_data)-1):\n",
    "            features.append(Dictionary_data[str(i)][idx])\n",
    "            #print(len(features) )\n",
    "            \n",
    "        return np.array(features,dtype=\"float32\" ), np.array( Dictionary_data[\"label\"][idx],dtype=\"float32\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b9fb530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.6889977,  0.7223266, 16.72847  ], dtype=float32),\n",
       " array(0., dtype=float32))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_train = MyDataSet_train( Dictionary_data )\n",
    "\n",
    "Batch_number = 1024*5\n",
    "\n",
    "Data_train[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b321da71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_loader = DataLoader(Data_train,batch_size=Batch_number, shuffle=True,num_workers = 3)\n",
    "train_loader = DataLoader(Data_train,batch_size=Batch_number, shuffle=True)\n",
    "\n",
    "model = NN_pileup()\n",
    "\n",
    "Adam_weight_decay = 0.002\n",
    "learning_ratio = 0.005\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_ratio , weight_decay=Adam_weight_decay ) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#torch.nn.functional.binary_cross_entropy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a2ae3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Loss: 8.0410\n",
      "Epoch [2/40], Loss: 5.9632\n",
      "Epoch [3/40], Loss: 5.4223\n",
      "Epoch [4/40], Loss: 5.2912\n",
      "Epoch [5/40], Loss: 5.2181\n",
      "Epoch [6/40], Loss: 5.1965\n",
      "Epoch [7/40], Loss: 5.1679\n",
      "Epoch [8/40], Loss: 5.1458\n",
      "Epoch [9/40], Loss: 5.1306\n",
      "Epoch [10/40], Loss: 5.1158\n",
      "Epoch [11/40], Loss: 5.0996\n",
      "Epoch [12/40], Loss: 5.0892\n",
      "Epoch [13/40], Loss: 5.0818\n",
      "Epoch [14/40], Loss: 5.0718\n",
      "Epoch [15/40], Loss: 5.0499\n",
      "Epoch [16/40], Loss: 5.0512\n",
      "Epoch [17/40], Loss: 5.0538\n",
      "Epoch [18/40], Loss: 5.0525\n",
      "Epoch [19/40], Loss: 5.0351\n",
      "Epoch [20/40], Loss: 5.0309\n",
      "Epoch [21/40], Loss: 5.0413\n",
      "Epoch [22/40], Loss: 5.0383\n",
      "Epoch [23/40], Loss: 5.0351\n",
      "Epoch [24/40], Loss: 5.0164\n",
      "Epoch [25/40], Loss: 5.0269\n",
      "Epoch [26/40], Loss: 5.0240\n",
      "Epoch [27/40], Loss: 5.0195\n",
      "Epoch [28/40], Loss: 5.0191\n",
      "Epoch [29/40], Loss: 5.0200\n",
      "Epoch [30/40], Loss: 5.0141\n",
      "Epoch [31/40], Loss: 5.0105\n",
      "Epoch [32/40], Loss: 4.9996\n",
      "Epoch [33/40], Loss: 5.0027\n",
      "Epoch [34/40], Loss: 5.0026\n",
      "Epoch [35/40], Loss: 4.9840\n",
      "Epoch [36/40], Loss: 5.0035\n",
      "Epoch [37/40], Loss: 5.0017\n",
      "Epoch [38/40], Loss: 4.9931\n",
      "Epoch [39/40], Loss: 4.9904\n",
      "Epoch [40/40], Loss: 4.9950\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epoch_loss=0\n",
    "num_epochs= 40\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        #data = data.to(device)\n",
    "        #print(data[0])\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data[0])\n",
    "        out = out.view(-1, out.shape[-1])\n",
    "        \n",
    "        #labels = torch.tensor(data.y, dtype=torch.long).to(device) \n",
    "        labels = data[1]\n",
    "        #print(out.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        labels = torch.reshape(labels, (int(list(labels.shape)[0]),1))\n",
    "        #loss = criterion(out, labels)\n",
    "        loss = torch.nn.functional.binary_cross_entropy(out, labels)\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c493c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e39cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "36d8620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float32\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "bb = np.array([1,2.2])\n",
    "print(bb.dtype)\n",
    "print( (bb.astype(\"float32\")).dtype )\n",
    "print(bb.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1461c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ee806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61e38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb3559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780e9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
